{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implement from sklearn package"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huodi\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2717: DtypeWarning: Columns (19,47) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "loans = pd.read_csv('lending-club-data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'member_id', 'loan_amnt', 'funded_amnt', 'funded_amnt_inv',\n",
       "       'term', 'int_rate', 'installment', 'grade', 'sub_grade', 'emp_title',\n",
       "       'emp_length', 'home_ownership', 'annual_inc', 'is_inc_v', 'issue_d',\n",
       "       'loan_status', 'pymnt_plan', 'url', 'desc', 'purpose', 'title',\n",
       "       'zip_code', 'addr_state', 'dti', 'delinq_2yrs', 'earliest_cr_line',\n",
       "       'inq_last_6mths', 'mths_since_last_delinq', 'mths_since_last_record',\n",
       "       'open_acc', 'pub_rec', 'revol_bal', 'revol_util', 'total_acc',\n",
       "       'initial_list_status', 'out_prncp', 'out_prncp_inv', 'total_pymnt',\n",
       "       'total_pymnt_inv', 'total_rec_prncp', 'total_rec_int',\n",
       "       'total_rec_late_fee', 'recoveries', 'collection_recovery_fee',\n",
       "       'last_pymnt_d', 'last_pymnt_amnt', 'next_pymnt_d', 'last_credit_pull_d',\n",
       "       'collections_12_mths_ex_med', 'mths_since_last_major_derog',\n",
       "       'policy_code', 'not_compliant', 'status', 'inactive_loans', 'bad_loans',\n",
       "       'emp_length_num', 'grade_num', 'sub_grade_num', 'delinq_2yrs_zero',\n",
       "       'pub_rec_zero', 'collections_12_mths_zero', 'short_emp',\n",
       "       'payment_inc_ratio', 'final_d', 'last_delinq_none', 'last_record_none',\n",
       "       'last_major_derog_none'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loans.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modify the target column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loans[\"safe_loans\"] = loans[\"bad_loans\"].apply(lambda x: +1 if x==0 else -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Selecting features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "target = 'safe_loans'\n",
    "features = ['grade',                     # grade of the loan (categorical)\n",
    "            'sub_grade_num',             # sub-grade of the loan as a number from 0 to 1\n",
    "            'short_emp',                 # one year or less of employment\n",
    "            'emp_length_num',            # number of years of employment\n",
    "            'home_ownership',            # home_ownership status: own, mortgage or rent\n",
    "            'dti',                       # debt to income ratio\n",
    "            'purpose',                   # the purpose of the loan\n",
    "            'payment_inc_ratio',         # ratio of the monthly payment to income\n",
    "            'delinq_2yrs',               # number of delinquincies\n",
    "             'delinq_2yrs_zero',          # no delinquincies in last 2 years\n",
    "            'inq_last_6mths',            # number of creditor inquiries in last 6 months\n",
    "            'last_delinq_none',          # has borrower had a delinquincy\n",
    "            'last_major_derog_none',     # has borrower had 90 day or worse rating\n",
    "            'open_acc',                  # number of open credit accounts\n",
    "            'pub_rec',                   # number of derogatory public records\n",
    "            'pub_rec_zero',              # no derogatory public records\n",
    "            'revol_util',                # percent of available credit being used\n",
    "            'total_rec_late_fee',        # total late fees received to day\n",
    "            'int_rate',                  # interest rate of the loan\n",
    "            'total_rec_int',             # interest received to date\n",
    "            'annual_inc',                # annual income of borrower\n",
    "            'funded_amnt',               # amount committed to the loan\n",
    "            'funded_amnt_inv',           # amount committed by investors for the loan\n",
    "            'installment',               # monthly payment owed by the borrower\n",
    "           ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Skipping observations with missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "loans = loans[features + [target]].dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import json \n",
    "with open (\"module-8-assignment-1-validation-idx.json\", \"r\") as f:\n",
    "    valid_idx = json.load(f)\n",
    "with open (\"module-8-assignment-1-train-idx.json\", \"r\") as f:\n",
    "    train_idx = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loans = pd.get_dummies(loans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "validation_data = loans.iloc[valid_idx]\n",
    "train_data = loans.iloc[train_idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gradient boosted tree classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gradient boosted trees are a powerful variant of boosting methods; they have been used to win many Kaggle competitions, and have been widely used in industry. We will explore the predictive power of multiple decision trees as opposed to a single decision tree."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now train models to predict safe_loans using the features above. In this section, we will experiment with training an ensemble of 5 trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's grab 2 positive examples and 2 negative examples. In SFrame, that would be:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sub_grade_num</th>\n",
       "      <th>short_emp</th>\n",
       "      <th>emp_length_num</th>\n",
       "      <th>dti</th>\n",
       "      <th>payment_inc_ratio</th>\n",
       "      <th>delinq_2yrs</th>\n",
       "      <th>delinq_2yrs_zero</th>\n",
       "      <th>inq_last_6mths</th>\n",
       "      <th>last_delinq_none</th>\n",
       "      <th>last_major_derog_none</th>\n",
       "      <th>...</th>\n",
       "      <th>purpose_debt_consolidation</th>\n",
       "      <th>purpose_home_improvement</th>\n",
       "      <th>purpose_house</th>\n",
       "      <th>purpose_major_purchase</th>\n",
       "      <th>purpose_medical</th>\n",
       "      <th>purpose_moving</th>\n",
       "      <th>purpose_other</th>\n",
       "      <th>purpose_small_business</th>\n",
       "      <th>purpose_vacation</th>\n",
       "      <th>purpose_wedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>29.44</td>\n",
       "      <td>6.30496</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12.19</td>\n",
       "      <td>13.49520</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>13.97</td>\n",
       "      <td>2.96736</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>16.33</td>\n",
       "      <td>1.90524</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 45 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    sub_grade_num  short_emp  emp_length_num    dti  payment_inc_ratio  \\\n",
       "22            0.2          0               3  29.44            6.30496   \n",
       "26            0.6          1               1  12.19           13.49520   \n",
       "24            0.4          0               3  13.97            2.96736   \n",
       "41            1.0          0              11  16.33            1.90524   \n",
       "\n",
       "    delinq_2yrs  delinq_2yrs_zero  inq_last_6mths  last_delinq_none  \\\n",
       "22          0.0               1.0             0.0                 1   \n",
       "26          0.0               1.0             0.0                 1   \n",
       "24          3.0               0.0             0.0                 0   \n",
       "41          0.0               1.0             0.0                 1   \n",
       "\n",
       "    last_major_derog_none       ...         purpose_debt_consolidation  \\\n",
       "22                      1       ...                                  0   \n",
       "26                      1       ...                                  0   \n",
       "24                      1       ...                                  0   \n",
       "41                      1       ...                                  1   \n",
       "\n",
       "    purpose_home_improvement  purpose_house  purpose_major_purchase  \\\n",
       "22                         0              0                       0   \n",
       "26                         0              0                       0   \n",
       "24                         0              0                       0   \n",
       "41                         0              0                       0   \n",
       "\n",
       "    purpose_medical  purpose_moving  purpose_other  purpose_small_business  \\\n",
       "22                0               0              0                       0   \n",
       "26                0               0              0                       0   \n",
       "24                0               0              1                       0   \n",
       "41                0               0              0                       0   \n",
       "\n",
       "    purpose_vacation  purpose_wedding  \n",
       "22                 0                0  \n",
       "26                 0                0  \n",
       "24                 0                0  \n",
       "41                 0                0  \n",
       "\n",
       "[4 rows x 45 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_safe_loans = validation_data[validation_data[target] == 1]\n",
    "validation_risky_loans = validation_data[validation_data[target] == -1]\n",
    "\n",
    "sample_validation_data_risky = validation_risky_loans[0:2]\n",
    "sample_validation_data_safe = validation_safe_loans[0:2]\n",
    "\n",
    "sample_validation_data = sample_validation_data_safe.append(sample_validation_data_risky)\n",
    "sample_validation_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each row in the sample_validation_data, write code to make model_5 predict whether or not the loan is classified as a safe loan. (Hint: if you are using scikit-learn, you can use the .predict() method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sklearn\n",
    "import sklearn.ensemble\n",
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model_5 = GradientBoostingClassifier(max_depth = 6, n_estimators=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
       "              learning_rate=0.1, loss='deviance', max_depth=6,\n",
       "              max_features=None, max_leaf_nodes=None,\n",
       "              min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "              min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "              n_estimators=5, presort='auto', random_state=None,\n",
       "              subsample=1.0, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_5.fit(train_data.drop(\"safe_loans\",1), train_data[\"safe_loans\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1,  1, -1,  1], dtype=int64)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_5.predict(sample_validation_data.drop(\"safe_loans\",1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22    1\n",
       "26    1\n",
       "24   -1\n",
       "41   -1\n",
       "Name: safe_loans, dtype: int64"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_validation_data[\"safe_loans\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prediction Probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.41642331,  0.58357669],\n",
       "       [ 0.46949689,  0.53050311],\n",
       "       [ 0.53807792,  0.46192208],\n",
       "       [ 0.39591639,  0.60408361]])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_5.predict_proba(sample_validation_data.drop(\"safe_loans\",1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluating the model on the validation data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate the accuracy of the model_5 on the validation_data. (Hint: if you are using scikit-learn, you can use the .score() method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.66124515295131414"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_5.score(X= valid_data.drop(\"safe_loans\",1),y=valid_data[\"safe_loans\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the number of false positives made by the model on the validation_data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1654"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "false_pos = sum(model_5.predict(validation_data.drop(\"safe_loans\",1)) > validation_data[\"safe_loans\"])\n",
    "false_pos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the number of false negatives made by the model on the validation_data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1491"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "false_neg = sum(model_5.predict(validation_data.drop(\"safe_loans\",1)) < validation_data[\"safe_loans\"])\n",
    "false_neg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comparison with decision trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the cost of mistakes made by model_5 on the validation_data.\n",
    "<br \\> Assume a cost of 10,000 per false negative.\n",
    "<br \\> Assume a cost of 20,000 per false positive."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the cost of mistakes made by model_5 on the validation_data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "47990000"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cost = false_neg * 10000 + false_pos* 20000\n",
    "cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49420000"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cost_old = 10000 * 1936  + 20000 * 1503\n",
    "cost_old"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare the cost of the mistakes made by the boosted trees model with the decision tree model. The extra 3% improvement in prediction accuracy can translate to several million dollars! And, it was so easy to get by simply boosting our decision trees."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Most positive & negative loans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huodi\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "validation_data[\"predictions\"] = model_5.predict_proba(validation_data.drop(\"safe_loans\",1))[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>grade_A</th>\n",
       "      <th>grade_B</th>\n",
       "      <th>grade_C</th>\n",
       "      <th>grade_D</th>\n",
       "      <th>predictions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8021</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.673059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15170</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.661468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15072</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.661468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90263</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.661468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7650</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.661468</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       grade_A  grade_B  grade_C  grade_D  predictions\n",
       "8021         1        0        0        0     0.673059\n",
       "15170        1        0        0        0     0.661468\n",
       "15072        1        0        0        0     0.661468\n",
       "90263        1        0        0        0     0.661468\n",
       "7650         1        0        0        0     0.661468"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_data[['grade_A','grade_B','grade_C','grade_D','predictions']].sort_values('predictions', ascending = False).head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>grade_A</th>\n",
       "      <th>grade_B</th>\n",
       "      <th>grade_C</th>\n",
       "      <th>grade_D</th>\n",
       "      <th>predictions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>84921</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.315973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101746</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.315973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27502</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.312806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58794</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.307334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84508</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.307334</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        grade_A  grade_B  grade_C  grade_D  predictions\n",
       "84921         0        0        1        0     0.315973\n",
       "101746        0        0        0        1     0.315973\n",
       "27502         0        0        1        0     0.312806\n",
       "58794         0        0        1        0     0.307334\n",
       "84508         0        0        1        0     0.307334"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_data[['grade_A','grade_B','grade_C','grade_D','predictions']].sort_values('predictions', ascending = False).tail(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Effects of adding more trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
       "              learning_rate=0.1, loss='deviance', max_depth=6,\n",
       "              max_features=None, max_leaf_nodes=None,\n",
       "              min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "              min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "              n_estimators=10, presort='auto', random_state=None,\n",
       "              subsample=1.0, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_10 = GradientBoostingClassifier(n_estimators=10, max_depth=6)\n",
    "model_10.fit(train_data.drop('safe_loans',1), train_data['safe_loans'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
       "              learning_rate=0.1, loss='deviance', max_depth=6,\n",
       "              max_features=None, max_leaf_nodes=None,\n",
       "              min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "              min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "              n_estimators=50, presort='auto', random_state=None,\n",
       "              subsample=1.0, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_50 = GradientBoostingClassifier(n_estimators=50, max_depth=6)\n",
    "model_50.fit(train_data.drop('safe_loans',1), train_data['safe_loans'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
       "              learning_rate=0.1, loss='deviance', max_depth=6,\n",
       "              max_features=None, max_leaf_nodes=None,\n",
       "              min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "              min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "              n_estimators=100, presort='auto', random_state=None,\n",
       "              subsample=1.0, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_100 = GradientBoostingClassifier(n_estimators=100, max_depth=6)\n",
    "model_100.fit(train_data.drop('safe_loans',1), train_data['safe_loans'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
       "              learning_rate=0.1, loss='deviance', max_depth=6,\n",
       "              max_features=None, max_leaf_nodes=None,\n",
       "              min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "              min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "              n_estimators=200, presort='auto', random_state=None,\n",
       "              subsample=1.0, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_200 = GradientBoostingClassifier(n_estimators=200, max_depth=6)\n",
    "model_200.fit(train_data.drop('safe_loans',1), train_data['safe_loans'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
       "              learning_rate=0.1, loss='deviance', max_depth=6,\n",
       "              max_features=None, max_leaf_nodes=None,\n",
       "              min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "              min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "              n_estimators=500, presort='auto', random_state=None,\n",
       "              subsample=1.0, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_500 = GradientBoostingClassifier(n_estimators=500, max_depth=6)\n",
    "model_500.fit(train_data.drop('safe_loans',1), train_data['safe_loans'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.66544592847910389"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_10.score(validation_data.drop(['safe_loans','predictions'],1), validation_data['safe_loans'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.68354157690650585"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_50.score(validation_data.drop(['safe_loans','predictions'],1), validation_data['safe_loans'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.69054286945282206"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_100.score(validation_data.drop(['safe_loans','predictions'],1), validation_data['safe_loans'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.68601895734597151"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_200.score(validation_data.drop(['safe_loans','predictions'],1), validation_data['safe_loans'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.68709607927617411"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_500.score(validation_data.drop(['safe_loans','predictions'],1), validation_data['safe_loans'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot the training and validation error vs. number of trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "def make_figure(dim, title, xlabel, ylabel, legend):\n",
    "    plt.rcParams['figure.figsize'] = dim\n",
    "    plt.title(title)\n",
    "    plt.xlabel(xlabel)\n",
    "    plt.ylabel(ylabel)\n",
    "    if legend is not None:\n",
    "        plt.legend(loc=legend, prop={'size':15})\n",
    "    plt.rcParams.update({'font.size': 16})\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_err_10 = 1 - model_10.score(train_data.drop('safe_loans',1), train_data['safe_loans'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_err_50 = 1 - model_50.score(train_data.drop('safe_loans',1), train_data['safe_loans'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_err_100 = 1 - model_100.score(train_data.drop('safe_loans',1), train_data['safe_loans'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_err_200 = 1 - model_200.score(train_data.drop('safe_loans',1), train_data['safe_loans'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_err_500 = 1 - model_500.score(train_data.drop('safe_loans',1), train_data['safe_loans'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "validation_err_10 = 1 - model_10.score(validation_data.drop(['safe_loans','predictions'],1), validation_data['safe_loans'])\n",
    "validation_err_50 = 1 - model_50.score(validation_data.drop(['safe_loans','predictions'],1), validation_data['safe_loans'])\n",
    "validation_err_100 = 1 - model_100.score(validation_data.drop(['safe_loans','predictions'],1), validation_data['safe_loans'])\n",
    "validation_err_200 = 1 - model_200.score(validation_data.drop(['safe_loans','predictions'],1), validation_data['safe_loans'])\n",
    "validation_err_500 = 1 - model_500.score(validation_data.drop(['safe_loans','predictions'],1), validation_data['safe_loans'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training_errors = [train_err_10, train_err_50, train_err_100, train_err_200, train_err_500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "validation_errors = [validation_err_10, validation_err_50, validation_err_100, validation_err_200, validation_err_500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZsAAAELCAYAAAAP/iu7AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xc4adc90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot([10, 50, 100, 200, 500], training_errors, linewidth=4.0, label='Training error')\n",
    "plt.plot([10, 50, 100, 200, 500], validation_errors, linewidth=4.0, label='Validation error')\n",
    "\n",
    "make_figure(dim=(10,5), title='Error vs number of trees',\n",
    "            xlabel='Number of trees',\n",
    "            ylabel='Classification error',\n",
    "            legend='best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Boosting from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huodi\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2717: DtypeWarning: Columns (19,47) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "loans = pd.read_csv('lending-club-data.csv')\n",
    "loans['safe_loans'] = loans['bad_loans'].apply(lambda x : +1 if x==0 else -1)\n",
    "loans.drop('bad_loans',1)\n",
    "target = 'safe_loans'\n",
    "\n",
    "features = ['grade',              # grade of the loan\n",
    "            'term',               # the term of the loan\n",
    "            'home_ownership',     # home ownership status: own, mortgage or rent\n",
    "            'emp_length',         # number of years of employment\n",
    "           ]\n",
    "loans = loans[features + [target]]\n",
    "loans= pd.get_dummies(loans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "with open (\"module-8-assignment-2-train-idx.json\", \"r\") as f:\n",
    "    train_idx = json.load(f)\n",
    "    \n",
    "with open (\"module-8-assignment-2-test-idx.json\", \"r\") as f:\n",
    "    test_idx = json.load(f)\n",
    "train_data = loans.iloc[train_idx].reset_index()\n",
    "test_data = loans.iloc[test_idx].reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_data = train_data.drop(\"index\",1)\n",
    "test_data = test_data.drop(\"index\", 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Weighted decision trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def intermediate_node_weighted_mistakes(labels_in_node, data_weights):\n",
    "    # Sum the weights of all entries with label +1\n",
    "    total_weight_positive = sum(data_weights[labels_in_node == +1])\n",
    "    \n",
    "    # Weight of mistakes for predicting all -1's is equal to the sum above\n",
    "    ### YOUR CODE HERE\n",
    "    weighted_mistakes_all_negative = total_weight_positive\n",
    "    \n",
    "    # Sum the weights of all entries with label -1\n",
    "    ### YOUR CODE HERE\n",
    "    total_weight_negative = sum(data_weights[labels_in_node == -1])\n",
    "    \n",
    "    # Weight of mistakes for predicting all +1's is equal to the sum above\n",
    "    ### YOUR CODE HERE\n",
    "    weighted_mistakes_all_positive = total_weight_negative\n",
    "    \n",
    "    # Return the tuple (weight, class_label) representing the lower of the two weights\n",
    "    #    class_label should be an integer of value +1 or -1.\n",
    "    # If the two weights are identical, return (weighted_mistakes_all_positive,+1)\n",
    "    ### YOUR CODE HERE\n",
    "    if weighted_mistakes_all_negative < weighted_mistakes_all_positive:\n",
    "        return (weighted_mistakes_all_negative, -1)\n",
    "    else: \n",
    "        return (weighted_mistakes_all_positive, +1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function to pick best feature to split on"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function best_splitting_feature should now accept an extra parameter data_weights to take account of weights of data points. Instead of computing the number of mistakes in the left and right side of the split, we compute the weight of mistakes for both sides, add up the two weights, and divide it by the total weight of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# If the data is identical in each feature, this function should return None\n",
    "\n",
    "def best_splitting_feature(data, features, target, data_weights):\n",
    "    \n",
    "    # These variables will keep track of the best feature and the corresponding error\n",
    "    best_feature = None\n",
    "    best_error = float('+inf') \n",
    "    num_points = float(len(data))\n",
    "\n",
    "    # Loop through each feature to consider splitting on that feature\n",
    "    for feature in features:\n",
    "        \n",
    "        # The left split will have all data points where the feature value is 0\n",
    "        # The right split will have all data points where the feature value is 1\n",
    "        left_split = data[data[feature] == 0]\n",
    "        right_split = data[data[feature] == 1]\n",
    "        \n",
    "        # Apply the same filtering to data_weights to create left_data_weights, right_data_weights\n",
    "        ## YOUR CODE HERE\n",
    "        left_data_weights = data_weights[data[feature] == 0]\n",
    "        right_data_weights = data_weights[data[feature] == 1]\n",
    "                    \n",
    "        # DIFFERENT HERE\n",
    "        # Calculate the weight of mistakes for left and right sides\n",
    "        ## YOUR CODE HERE\n",
    "        left_weighted_mistakes, left_class = intermediate_node_weighted_mistakes(left_split[target], left_data_weights)\n",
    "        right_weighted_mistakes, right_class = intermediate_node_weighted_mistakes(right_split[target], right_data_weights)\n",
    "        \n",
    "        # DIFFERENT HERE\n",
    "        # Compute weighted error by computing\n",
    "        #  ( [weight of mistakes (left)] + [weight of mistakes (right)] ) / [total weight of all data points]\n",
    "        ## YOUR CODE HERE\n",
    "        error = (left_weighted_mistakes + right_weighted_mistakes)/sum(data_weights)\n",
    "        \n",
    "        # If this is the best error we have found so far, store the feature and the error\n",
    "        if error < best_error:\n",
    "            best_feature = feature\n",
    "            best_error = error\n",
    "    \n",
    "    # Return the best feature we found\n",
    "    return best_feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Building the tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_leaf(target_values, data_weights):\n",
    "    \n",
    "    # Create a leaf node\n",
    "    leaf = {'splitting_feature' : None,\n",
    "            'is_leaf': True}\n",
    "    \n",
    "    # Computed weight of mistakes.\n",
    "    # Store the predicted class (1 or -1) in leaf['prediction']\n",
    "    weighted_error, best_class = intermediate_node_weighted_mistakes(target_values, data_weights)\n",
    "    leaf['prediction'] = best_class ## YOUR CODE HERE\n",
    "    \n",
    "    return leaf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Now write a function that learns a weighted decision tree recursively and implements 3 stopping conditions:\n",
    "<br \\> All data points in a node are from the same class. No more features to split on. Stop growing the tree when the tree depth reaches max_depth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def weighted_decision_tree_create(data, features, target, data_weights, current_depth = 1, max_depth = 10):\n",
    "    remaining_features = features[:] # Make a copy of the features.\n",
    "    target_values = data[target]\n",
    "    print (\"--------------------------------------------------------------------\")\n",
    "    print (\"Subtree, depth = %s (%s data points).\" % (current_depth, len(target_values)))\n",
    "    \n",
    "    # Stopping condition 1. Error is 0.\n",
    "    if intermediate_node_weighted_mistakes(target_values, data_weights)[0] <= 1e-15:\n",
    "        print (\"Stopping condition 1 reached.\")               \n",
    "        return create_leaf(target_values, data_weights)\n",
    "    \n",
    "    # Stopping condition 2. No more features.\n",
    "    if remaining_features == []:\n",
    "        print (\"Stopping condition 2 reached.\")                \n",
    "        return create_leaf(target_values, data_weights)    \n",
    "    \n",
    "    # Additional stopping condition (limit tree depth)\n",
    "    if current_depth > max_depth:\n",
    "        print (\"Reached maximum depth. Stopping for now.\")\n",
    "        return create_leaf(target_values, data_weights)\n",
    "    \n",
    "    # If all the datapoints are the same, splitting_feature will be None. Create a leaf\n",
    "    splitting_feature = best_splitting_feature(data, features, target, data_weights)\n",
    "    remaining_features.remove(splitting_feature)\n",
    "        \n",
    "    left_split = data[data[splitting_feature] == 0]\n",
    "    right_split = data[data[splitting_feature] == 1]\n",
    "    \n",
    "    left_data_weights = data_weights[data[splitting_feature] == 0]\n",
    "    right_data_weights = data_weights[data[splitting_feature] == 1]\n",
    "    \n",
    "    print (\"Split on feature %s. (%s, %s)\" % (\\\n",
    "              splitting_feature, len(left_split), len(right_split)))\n",
    "    \n",
    "    # Create a leaf node if the split is \"perfect\"\n",
    "    if len(left_split) == len(data):\n",
    "        print (\"Creating leaf node.\")\n",
    "        return create_leaf(left_split[target], data_weights)\n",
    "    if len(right_split) == len(data):\n",
    "        print (\"Creating leaf node.\")\n",
    "        return create_leaf(right_split[target], data_weights)\n",
    "    \n",
    "    # Repeat (recurse) on left and right subtrees\n",
    "    left_tree = weighted_decision_tree_create(\n",
    "        left_split, remaining_features, target, left_data_weights, current_depth + 1, max_depth)\n",
    "    right_tree = weighted_decision_tree_create(\n",
    "        right_split, remaining_features, target, right_data_weights, current_depth + 1, max_depth)\n",
    "    \n",
    "    return {'is_leaf'          : False, \n",
    "            'prediction'       : None,\n",
    "            'splitting_feature': splitting_feature,\n",
    "            'left'             : left_tree, \n",
    "            'right'            : right_tree}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, write a recursive function to count the nodes in your tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def count_nodes(tree):\n",
    "    if tree['is_leaf']:\n",
    "        return 1\n",
    "    return 1 + count_nodes(tree['left']) + count_nodes(tree['right'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Making predictions with a weighted decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def classify(tree, x, annotate = False):   \n",
    "    # If the node is a leaf node.\n",
    "    if tree['is_leaf']:\n",
    "        if annotate: \n",
    "            print (\"At leaf, predicting %s\" % tree['prediction'])\n",
    "        return tree['prediction'] \n",
    "    else:\n",
    "        # Split on feature.\n",
    "        split_feature_value = x[tree['splitting_feature']]\n",
    "        if annotate: \n",
    "            print (\"Split on %s = %s\" % (tree['splitting_feature'], split_feature_value))\n",
    "        if split_feature_value == 0:\n",
    "            return classify(tree['left'], x, annotate)\n",
    "        else:\n",
    "            return classify(tree['right'], x, annotate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluating the tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluate_classification_error(tree, data):\n",
    "    # Apply the classify(tree, x) to each row in your data\n",
    "    data['prediction'] = [classify(tree,a) for a in data.to_dict(orient = 'records')]\n",
    "    \n",
    "    # Once you've made the predictions, calculate the classification error\n",
    "    return (data['prediction'] != data[target]).sum() / float(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 1 (37224 data points).\n",
      "Split on feature home_ownership_RENT. (20514, 16710)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (20514 data points).\n",
      "Split on feature grade_F. (19613, 901)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 3 (19613 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 3 (901 data points).\n",
      "Stopping condition 1 reached.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (16710 data points).\n",
      "Split on feature grade_D. (13315, 3395)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 3 (13315 data points).\n",
      "Stopping condition 1 reached.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 3 (3395 data points).\n",
      "Stopping condition 1 reached.\n"
     ]
    }
   ],
   "source": [
    "# Assign weights\n",
    "example_data_weights = np.ones(10*1).tolist() + [0.]*(len(train_data) - 20) + np.ones(1*10).tolist()\n",
    "example_data_weights = np.array(example_data_weights)\n",
    "features = [i for i in train_data.columns]\n",
    "features.remove('safe_loans')\n",
    "\n",
    "# Train a weighted decision tree model.\n",
    "small_data_decision_tree_subset_20 = weighted_decision_tree_create(train_data, features, target,\n",
    "                         example_data_weights, max_depth=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.050000000000000003"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subset_20 = train_data.head(10).append(train_data.tail(10))\n",
    "small_data_decision_tree_subset_20['splitting_feature']\n",
    "evaluate_classification_error(small_data_decision_tree_subset_20, subset_20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model small_data_decision_tree_subset_20 performs a lot better on subset_20 than on train_data. So, what does this mean? The points with higher weights are the ones that are more important during the training process of the weighted decision tree. The points with zero weights are basically ignored during training. Quiz Question: Will you get the same model as small_data_decision_tree_subset_20 if you trained a decision tree with only the 20 data points with non-zero weights from the set of points in subset_20?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.48124865678057166"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_classification_error(small_data_decision_tree_subset_20, train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Implementing your own Adaboost (on decision stumps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from math import log\n",
    "from math import exp\n",
    "\n",
    "def adaboost_with_tree_stumps(data, features, target, num_tree_stumps):\n",
    "    # start with unweighted data\n",
    "    alpha = np.ones(len(data)*1)\n",
    "    weights = []\n",
    "    tree_stumps = []\n",
    "    target_values = data[target]\n",
    "    \n",
    "    for t in range(num_tree_stumps):\n",
    "        print ('=====================================================')\n",
    "        print ('Adaboost Iteration %d' % t)\n",
    "        print ('=====================================================')        \n",
    "        # Learn a weighted decision tree stump. Use max_depth=1\n",
    "        tree_stump = weighted_decision_tree_create(data, features, target, data_weights=alpha, max_depth=1)\n",
    "        tree_stumps.append(tree_stump)\n",
    "        \n",
    "        # Make predictions\n",
    "        data['prediction'] = [classify(tree_stump,a) for a in data.to_dict(orient = 'records')]\n",
    "        \n",
    "        # Produce a Boolean array indicating whether\n",
    "        # each data point was correctly classified\n",
    "        is_correct = data['prediction'] == target_values\n",
    "        is_wrong   = data['prediction'] != target_values\n",
    "        \n",
    "        # Compute weighted error\n",
    "        # YOUR CODE HERE\n",
    "        weighted_error = round(float(sum(a for i, a in enumerate(alpha) if is_wrong[i]))/sum(alpha),2)\n",
    "        \n",
    "        # Compute model coefficient using weighted error\n",
    "        # YOUR CODE HERE\n",
    "        weight = log((1-weighted_error)/weighted_error)/2\n",
    "        weights.append(weight)\n",
    "        \n",
    "        # Adjust weights on data point\n",
    "        adjustment = is_correct.apply(lambda is_correct : exp(-weight) if is_correct else exp(weight))\n",
    "        \n",
    "        # Scale alpha by multiplying by adjustment\n",
    "        # Then normalize data points weights\n",
    "        ## YOUR CODE HERE \n",
    "        sum_alpha = sum(alpha)\n",
    "        alpha = alpha*adjustment/sum_alpha\n",
    "    \n",
    "    return weights, tree_stumps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict_adaboost(stump_weights, tree_stumps, data):\n",
    "    scores = np.zeros(len(data)*1)\n",
    "    \n",
    "    for i, tree_stump in enumerate(tree_stumps):\n",
    "        data['prediction'] = [classify(tree_stump,a) for a in data.to_dict(orient = 'records')]\n",
    "        \n",
    "        # Accumulate predictions on scaores array\n",
    "        # YOUR CODE HERE\n",
    "        scores += stump_weights[i] * data['prediction']\n",
    "        data['scores'] = scores\n",
    "        \n",
    "    return data['scores'].apply(lambda score : +1 if score > 0 else -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====================================================\n",
      "Adaboost Iteration 0\n",
      "=====================================================\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 1 (37224 data points).\n",
      "Split on feature term_ 36 months. (9223, 28001)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (9223 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (28001 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "=====================================================\n",
      "Adaboost Iteration 1\n",
      "=====================================================\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 1 (37224 data points).\n",
      "Split on feature grade_A. (32094, 5130)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (32094 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (5130 data points).\n",
      "Reached maximum depth. Stopping for now.\n"
     ]
    }
   ],
   "source": [
    "stump_weights, tree_stumps = adaboost_with_tree_stumps(train_data, features, target, num_tree_stumps=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_stump(tree, name = 'root'):\n",
    "    split_name = tree['splitting_feature'] # split_name is something like 'term. 36 months'\n",
    "    if split_name is None:\n",
    "        print (\"(leaf, label: %s)\" % tree['prediction'])\n",
    "        return None\n",
    "    split_feature, split_value = split_name.split('_')\n",
    "    print ('                       %s' % name)\n",
    "    print ('         |---------------|----------------|')\n",
    "    print ('         |                                |')\n",
    "    print ('         |                                |')\n",
    "    print ('         |                                |')\n",
    "    print ('  [{0} == 0]               [{0} == 1]    '.format(split_name))\n",
    "    print ('         |                                |')\n",
    "    print ('         |                                |')\n",
    "    print ('         |                                |')\n",
    "    print ('    (%s)                   (%s)' \\\n",
    "        % (('leaf, label: ' + str(tree['left']['prediction']) if tree['left']['is_leaf'] else 'subtree'),\n",
    "           ('leaf, label: ' + str(tree['right']['prediction']) if tree['right']['is_leaf'] else 'subtree')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       root\n",
      "         |---------------|----------------|\n",
      "         |                                |\n",
      "         |                                |\n",
      "         |                                |\n",
      "  [term_ 36 months == 0]               [term_ 36 months == 1]    \n",
      "         |                                |\n",
      "         |                                |\n",
      "         |                                |\n",
      "    (leaf, label: -1)                   (leaf, label: 1)\n"
     ]
    }
   ],
   "source": [
    "print_stump(tree_stumps[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       root\n",
      "         |---------------|----------------|\n",
      "         |                                |\n",
      "         |                                |\n",
      "         |                                |\n",
      "  [grade_A == 0]               [grade_A == 1]    \n",
      "         |                                |\n",
      "         |                                |\n",
      "         |                                |\n",
      "    (leaf, label: -1)                   (leaf, label: 1)\n"
     ]
    }
   ],
   "source": [
    "print_stump(tree_stumps[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10 decision tree stumps with Adaboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====================================================\n",
      "Adaboost Iteration 0\n",
      "=====================================================\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 1 (37224 data points).\n",
      "Split on feature term_ 36 months. (9223, 28001)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (9223 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (28001 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "=====================================================\n",
      "Adaboost Iteration 1\n",
      "=====================================================\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 1 (37224 data points).\n",
      "Split on feature grade_A. (32094, 5130)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (32094 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (5130 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "=====================================================\n",
      "Adaboost Iteration 2\n",
      "=====================================================\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 1 (37224 data points).\n",
      "Split on feature grade_D. (30465, 6759)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (30465 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (6759 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "=====================================================\n",
      "Adaboost Iteration 3\n",
      "=====================================================\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 1 (37224 data points).\n",
      "Split on feature home_ownership_MORTGAGE. (19846, 17378)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (19846 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (17378 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "=====================================================\n",
      "Adaboost Iteration 4\n",
      "=====================================================\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 1 (37224 data points).\n",
      "Split on feature grade_B. (26858, 10366)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (26858 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (10366 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "=====================================================\n",
      "Adaboost Iteration 5\n",
      "=====================================================\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 1 (37224 data points).\n",
      "Split on feature grade_E. (33815, 3409)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (33815 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (3409 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "=====================================================\n",
      "Adaboost Iteration 6\n",
      "=====================================================\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 1 (37224 data points).\n",
      "Split on feature grade_A. (32094, 5130)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (32094 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (5130 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "=====================================================\n",
      "Adaboost Iteration 7\n",
      "=====================================================\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 1 (37224 data points).\n",
      "Split on feature grade_F. (35512, 1712)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (35512 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (1712 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "=====================================================\n",
      "Adaboost Iteration 8\n",
      "=====================================================\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 1 (37224 data points).\n",
      "Split on feature grade_D. (30465, 6759)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (30465 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (6759 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "=====================================================\n",
      "Adaboost Iteration 9\n",
      "=====================================================\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 1 (37224 data points).\n",
      "Split on feature grade_B. (26858, 10366)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (26858 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (10366 data points).\n",
      "Reached maximum depth. Stopping for now.\n"
     ]
    }
   ],
   "source": [
    "stump_weights, tree_stumps = adaboost_with_tree_stumps(train_data, features, target, num_tree_stumps=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
